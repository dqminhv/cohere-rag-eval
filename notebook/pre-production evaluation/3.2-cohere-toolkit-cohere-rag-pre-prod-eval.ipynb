{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This Jupyter notebook evaluates the performance of of the Cohere deployment within the Cohere toolkit using synthetic data. The notebook follows a series of steps to prepare the testing data, evaluate the RAG system's performance, and save the results.\n",
    "\n",
    "**Step 1: Load Synthetic Data**\n",
    "\n",
    "The notebook loads synthetic question-ground truth data generated by another notebook (`1-ragas-synthetic-test-data-generation.ipynb`).\n",
    "\n",
    "**Step 2: Feed Data to System and Extract Responses**\n",
    "\n",
    "The notebook feeds the synthetic questions into the RAG system and extracts the system's generated responses using the `2-chat-history-extraction.ipynb` notebook.\n",
    "\n",
    "**Step 3: Prepare Testing Data**\n",
    "\n",
    "The notebook prepares the testing data by:\n",
    "\n",
    "1. Loading the chat history extraction data from a CSV file (`test_dataset_hr_cohere_deployment_test.csv`) using a custom function `load_dataframe_with_list_column`.\n",
    "2. Loading the ground truth data from a JSON file (`test_dataset_hr.json`).\n",
    "3. Merging the two dataframes by the question content.\n",
    "4. Converting the dataframe to the RAGAS (RAG Augmented Search) dataset format using the `Dataset` class from the `datasets` library.\n",
    "\n",
    "**Step 4: Evaluate RAG System's Performance**\n",
    "\n",
    "The notebook evaluates the RAG system's performance using the `evaluate` function from the `ragas` library, which takes the prepared dataset and a list of metrics as input. The metrics used in this evaluation are:\n",
    "\n",
    "1. Answer relevancy\n",
    "2. Faithfulness\n",
    "3. Context recall\n",
    "4. Context precision\n",
    "\n",
    "**Step 5: Save Evaluated Results**\n",
    "\n",
    "The notebook saves the evaluated results to a CSV file (`eval_result_dataset_hr_cohere_deployment.csv`) using the `to_pandas` method.\n",
    "\n",
    "**Additional Features**\n",
    "\n",
    "The notebook also includes optional code for tracing runs with LangSmith, which requires signing up for an API key.\n",
    "\n",
    "**Custom Functions**\n",
    "\n",
    "The notebook defines several custom functions for working with dataframes containing list columns, including:\n",
    "\n",
    "1. `serialize_list`: serializes a list to a JSON string\n",
    "2. `deserialize_list`: deserializes a JSON string back into a list\n",
    "3. `save_dataframe_with_list_column`: saves a dataframe with a list column to a CSV file\n",
    "4. `load_dataframe_with_list_column`: loads a dataframe from a CSV file, restoring the list structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When saving the test data in the notebook 2-chat-history-extraction.ipynb, we serialized the contexts column. To load that file to a dataframe, we need a function to de-serialize it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def serialize_list(value):\n",
    "    \"\"\"Serializes a list to a JSON string.\"\"\"\n",
    "    return json.dumps(value)\n",
    "\n",
    "def deserialize_list(value):\n",
    "    \"\"\"Deserializes a JSON string back into a list.\"\"\"\n",
    "    return json.loads(value)\n",
    "\n",
    "def save_dataframe_with_list_column(df, filename):\n",
    "    \"\"\"Saves a DataFrame with a list column to a CSV file, preserving the list structure.\n",
    "\n",
    "    Args:\n",
    "        df: The DataFrame to save.\n",
    "        filename: The name of the output CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply the serialization function to the list column\n",
    "    df['contexts'] = df['contexts'].apply(serialize_list)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def load_dataframe_with_list_column(filename):\n",
    "    \"\"\"Loads a DataFrame from a CSV file, restoring the list structure.\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The loaded DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the DataFrame\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Apply the deserialization function to the list column\n",
    "    df['contexts'] = df['contexts'].apply(deserialize_list)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test data from the chat history extraction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from from_root import from_root\n",
    "file_name = \"test_dataset_hr_cohere_deployment_test.csv\"\n",
    "df_question_answer_contexts = load_dataframe_with_list_column(os.path.join(from_root(), \"data-test/test-dataset/\", file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ground truth from the test question set \n",
    "df_ground_truth = pd.read_json(os.path.join(from_root(), \"data-test/test-dataset/\", \"test_dataset_hr.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframe with the ground_truth by the question content\n",
    "data_to_test = pd.merge(df_question_answer_contexts[['question', 'answer', 'contexts']], df_ground_truth, on='question', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to RAGAS data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert testing data to RAGAS Dataset format\n",
    "from datasets import Dataset\n",
    "\n",
    "question = list(data_to_test['question'])\n",
    "answer = list(data_to_test['answer'])\n",
    "contexts = list(data_to_test['contexts'])\n",
    "ground_truth = list(data_to_test['ground_truth'])\n",
    "\n",
    "data = {\n",
    "    'question': question,\n",
    "    'answer': answer,\n",
    "    'contexts': contexts,\n",
    "    'ground_truth': ground_truth\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\n",
    "from langsmith import Client\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Cohere_RAG_Eval\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22734084a3a74946a24ce3b43e1a9825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.5457, 'faithfulness': 0.7483, 'context_recall': 0.3766, 'context_precision': 0.5714}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of adding a header image t...</td>\n",
       "      <td>I'm sorry, I could not find any information ab...</td>\n",
       "      <td>[Description#F4F5F7In a sentence or two, descr...</td>\n",
       "      <td>Adding a header image to a Confluence space en...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do employee engagement and disengagement d...</td>\n",
       "      <td>Employee engagement refers to the emotional co...</td>\n",
       "      <td>[Employee Engagement?Employee engagement refer...</td>\n",
       "      <td>Employee engagement and disengagement differ i...</td>\n",
       "      <td>0.871751</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What services does the Employee Assistance Pro...</td>\n",
       "      <td>The Employee Assistance Program (EAP) provides...</td>\n",
       "      <td>[take appropriate action to ensure a safe and ...</td>\n",
       "      <td>Employees can contact the Employee Assistance ...</td>\n",
       "      <td>0.984870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What training programs are offered in data sci...</td>\n",
       "      <td>Tech Innovators Inc. offers training programs ...</td>\n",
       "      <td>[training programs in cloud computing, data sc...</td>\n",
       "      <td>Courses covering financial analysis, budgeting...</td>\n",
       "      <td>0.989385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What resources should be added for new hires i...</td>\n",
       "      <td>I'm sorry, I could not find any information ab...</td>\n",
       "      <td>[Offers are extended promptly, and candidates ...</td>\n",
       "      <td>Add resources for new hires in the onboarding ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is Tech Innovators Inc.'s approach to wor...</td>\n",
       "      <td>Tech Innovators Inc. has a zero-tolerance poli...</td>\n",
       "      <td>[is the process for handling workplace harassm...</td>\n",
       "      <td>Tech Innovators Inc. has a zero-tolerance poli...</td>\n",
       "      <td>0.974083</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the significance of identifying growth...</td>\n",
       "      <td>I'm sorry, I could not find any information ab...</td>\n",
       "      <td>[No contexts]</td>\n",
       "      <td>Identifying growth areas in self-assessment is...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of adding a header image t...   \n",
       "1  How do employee engagement and disengagement d...   \n",
       "2  What services does the Employee Assistance Pro...   \n",
       "3  What training programs are offered in data sci...   \n",
       "4  What resources should be added for new hires i...   \n",
       "5  What is Tech Innovators Inc.'s approach to wor...   \n",
       "6  What is the significance of identifying growth...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  I'm sorry, I could not find any information ab...   \n",
       "1  Employee engagement refers to the emotional co...   \n",
       "2  The Employee Assistance Program (EAP) provides...   \n",
       "3  Tech Innovators Inc. offers training programs ...   \n",
       "4  I'm sorry, I could not find any information ab...   \n",
       "5  Tech Innovators Inc. has a zero-tolerance poli...   \n",
       "6  I'm sorry, I could not find any information ab...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Description#F4F5F7In a sentence or two, descr...   \n",
       "1  [Employee Engagement?Employee engagement refer...   \n",
       "2  [take appropriate action to ensure a safe and ...   \n",
       "3  [training programs in cloud computing, data sc...   \n",
       "4  [Offers are extended promptly, and candidates ...   \n",
       "5  [is the process for handling workplace harassm...   \n",
       "6                                      [No contexts]   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  Adding a header image to a Confluence space en...          0.000000   \n",
       "1  Employee engagement and disengagement differ i...          0.871751   \n",
       "2  Employees can contact the Employee Assistance ...          0.984870   \n",
       "3  Courses covering financial analysis, budgeting...          0.989385   \n",
       "4  Add resources for new hires in the onboarding ...          0.000000   \n",
       "5  Tech Innovators Inc. has a zero-tolerance poli...          0.974083   \n",
       "6  Identifying growth areas in self-assessment is...          0.000000   \n",
       "\n",
       "   faithfulness  context_recall  context_precision  \n",
       "0      1.000000        0.000000                0.0  \n",
       "1      0.714286        0.636364                1.0  \n",
       "2      1.000000        1.000000                1.0  \n",
       "3      1.000000        0.000000                0.0  \n",
       "4      0.666667        0.000000                1.0  \n",
       "5      0.857143        1.000000                1.0  \n",
       "6      0.000000        0.000000                0.0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result data\n",
    "file_name = \"eval_result_dataset_hr_cohere_deployment.csv\"\n",
    "result.to_pandas().to_csv(os.path.join(from_root(), \"data-test/test-dataset/\", file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
