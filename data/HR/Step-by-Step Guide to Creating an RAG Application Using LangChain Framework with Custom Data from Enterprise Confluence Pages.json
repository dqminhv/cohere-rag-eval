{"id": "1574296", "text": "Introduction\nThis guide provides a step-by-step process for creating a Retrieval-Augmented Generation (RAG) application using the LangChain framework. The application will be trained on custom data sourced from enterprise Confluence pages. RAG combines retrieval-based methods with generative models, leveraging both structured data and contextual understanding to generate accurate and relevant responses.\nPrerequisites\nBefore starting, ensure you have the following:\nBasic knowledge of Python and Natural Language Processing (NLP).\nAccess to the enterprise Confluence API or export files containing the Confluence data.\nInstallation of necessary libraries and tools:\nLangChain\nOpenAI or Hugging Face Transformers\nPinecone or another vector database for retrieval\nConfluence API library (e.g., atlassian-python-api)\nSetting Up the Environment\n3.1 Install Required Libraries\nbash\nCopy code\npip install langchain openai transformers atlassian-python-api pinecone-client\n3.2 Configure API Keys\nEnsure you have API keys for OpenAI/Hugging Face and Pinecone. Set them as environment variables or within your application:\npython\nCopy code\nimport os\n\u00a0\nos.environ['OPENAI_API_KEY'] = 'your-openai-api-key'\nos.environ['PINECONE_API_KEY'] = 'your-pinecone-api-key'\nData Extraction from Confluence\n4.1 Connect to Confluence API\npython\nCopy code\nfrom atlassian import Confluence\n\u00a0\nconfluence = Confluence(\n\u00a0\u00a0\u00a0 url='\nhttps://your-confluence-url\n',\n\u00a0\u00a0\u00a0 username='your-username',\n\u00a0\u00a0\u00a0 password='your-api-token'\n)\n4.2 Fetch Data from Confluence\nExtract the relevant pages or spaces:\npython\nCopy code\ndef fetch_confluence_data(space_key):\n\u00a0\u00a0\u00a0 pages = confluence.get_all_pages_from_space(space_key, start=0, limit=50, expand='body.storage')\n\u00a0\u00a0\u00a0 documents = []\n\u00a0\u00a0\u00a0 for page in pages:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 content = page['body']['storage']['value']\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 documents.append({\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 'title': page['title'],\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 'content': content\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 })\n\u00a0\u00a0\u00a0 return documents\n\u00a0\nspace_key = 'your-space-key'\ndocuments = fetch_confluence_data(space_key)\nData Preprocessing\n5.1 Clean and Prepare Data\npython\nCopy code\nfrom bs4 import BeautifulSoup\n\u00a0\ndef clean_html(html_content):\n\u00a0\u00a0\u00a0 soup = BeautifulSoup(html_content, 'html.parser')\n\u00a0\u00a0\u00a0 return soup.get_text(separator='\\n')\n\u00a0\ncleaned_documents = [{'title': doc['title'], 'content': clean_html(doc['content'])} for doc in documents]\n5.2 Split Documents into Chunks\npython\nCopy code\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\u00a0\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nchunks = []\n\u00a0\nfor doc in cleaned_documents:\n\u00a0\u00a0\u00a0 for chunk in text_splitter.split_text(doc['content']):\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 chunks.append({'title': doc['title'], 'content': chunk})\nIndexing Data for Retrieval\n6.1 Initialize Pinecone\npython\nCopy code\nimport pinecone\n\u00a0\npinecone.init(api_key=os.environ['PINECONE_API_KEY'], environment='us-west1-gcp')\n\u00a0\nindex_name = 'confluence-index'\npinecone.create_index(index_name, dimension=768)\n\u00a0\nindex = pinecone.Index(index_name)\n6.2 Embed and Index Data\npython\nCopy code\nfrom langchain.embeddings import OpenAIEmbeddings\n\u00a0\nembedder = OpenAIEmbeddings()\nfor i, chunk in enumerate(chunks):\n\u00a0\u00a0\u00a0 embedding = embedder.embed(chunk['content'])\n\u00a0\u00a0\u00a0 index.upsert([(str(i), embedding, {'title': chunk['title'], 'content': chunk['content']})])\nBuilding the RAG Application\n7.1 Define the Retrieval Function\npython\nCopy code\nfrom langchain.retrieval import PineconeRetriever\n\u00a0\nretriever = PineconeRetriever(index_name=index_name, embedder=embedder)\n\u00a0\ndef retrieve_documents(query):\n\u00a0\u00a0\u00a0 return retriever.retrieve(query)\n7.2 Generate Responses with LangChain\npython\nCopy code\nfrom langchain.llms import OpenAI\nfrom langchain.chains import RetrievalQA\n\u00a0\nllm = OpenAI(model='text-davinci-003')\n\u00a0\nqa_chain = RetrievalQA(retriever=retriever, llm=llm)\n\u00a0\ndef answer_query(query):\n\u00a0\u00a0\u00a0 result = qa_chain(query)\n\u00a0\u00a0\u00a0 return result['answer']\n\u00a0\n# Example usage\nquery = \"What is the company's policy on remote work?\"\nanswer = answer_query(query)\nprint(answer)\nTesting and Deployment\n8.1 Test the Application\nRun various queries to test the application's accuracy and relevance. Refine the data preprocessing, indexing, and retrieval as needed.\n8.2 Deploy the Application\nDeploy the application using a web framework (e.g., Flask, FastAPI) or integrate it into an existing enterprise system.\npython\nCopy code\nfrom flask import Flask, request, jsonify\n\u00a0\napp = Flask(__name__)\n\u00a0\n@app.route('/query', methods=['POST'])\ndef query():\n\u00a0\u00a0\u00a0 data = request.json\n\u00a0\u00a0\u00a0 query = data.get('query')\n\u00a0\u00a0\u00a0 answer = answer_query(query)\n\u00a0\u00a0\u00a0 return jsonify({'query': query, 'answer': answer})\n\u00a0\nif __name__ == '__main__':\n\u00a0\u00a0\u00a0 app.run(host='0.0.0.0', port=5000)\nConclusion\nBy following this step-by-step guide, you have created a RAG application using the LangChain framework trained on custom data from enterprise Confluence pages. This application leverages both retrieval and generative capabilities to provide accurate and contextually relevant responses, enhancing the overall decision-making process within your organization. Continuous testing and refinement will ensure the application's robustness and effectiveness.\n\u00a0", "Title": "Step-by-Step Guide to Creating an RAG Application Using LangChain Framework with Custom Data from Enterprise Confluence Pages", "Space": "HR"}