{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the cohere container database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .env file\n",
    "#pip install -U python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a SQL query\n",
    "cur.execute(\"SELECT * FROM citation_documents;\")\n",
    "#cur.execute(\"SELECT * FROM citation_documents;\")\n",
    "\n",
    "# Fetch the results\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What is the travel reimbursement policy at Tech Innovator Inc?', None, 'USER', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '94ee2d56-250a-46cc-b709-2e2c8a6b6da6', 0, True, '6ea2ab3a-4e65-48ed-bc4d-9bf6e9000a0e', datetime.datetime(2024, 8, 23, 7, 32, 30, 82017), datetime.datetime(2024, 8, 23, 7, 32, 30, 82017), None)\n",
      "('', None, 'CHATBOT', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '94ee2d56-250a-46cc-b709-2e2c8a6b6da6', 0, True, 'b8de4b06-1a0e-446b-9c46-8eaeb123c503', datetime.datetime(2024, 8, 23, 7, 33, 1, 577401), datetime.datetime(2024, 8, 23, 7, 33, 1, 577401), None)\n",
      "('Who wrote the finance documents?', None, 'USER', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 0, True, '60909156-e66a-40dc-ae3a-515faa982a80', datetime.datetime(2024, 8, 23, 15, 34, 59, 257051), datetime.datetime(2024, 8, 23, 15, 34, 59, 257051), None)\n",
      "(\"I don't have enough information to answer the question. You haven't provided any context about the finance documents, so I'm unable to determine who wrote them.\", '', 'CHATBOT', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 0, True, 'ca47751a-447a-4e6c-93d5-0fde8bc7cc3b', datetime.datetime(2024, 8, 23, 15, 35, 6, 762996), datetime.datetime(2024, 8, 23, 15, 35, 6, 762996), None)\n",
      "('Who wrote the finance documents?', None, 'USER', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 1, True, '8897a8e9-26a6-4847-b671-e80147e4390a', datetime.datetime(2024, 8, 23, 15, 36, 46, 148047), datetime.datetime(2024, 8, 23, 15, 36, 46, 148047), None)\n",
      "(\"I don't know. There is no information provided about who wrote the finance documents.\", '', 'CHATBOT', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 1, True, '2fb3964e-55e3-423d-abcf-23025606b3ca', datetime.datetime(2024, 8, 23, 15, 36, 47, 941122), datetime.datetime(2024, 8, 23, 15, 36, 47, 941122), None)\n",
      "('When will vendors receive payment after their delivery?', None, 'USER', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 2, True, 'ef7d86f1-f1e6-4c41-b3bf-988bfd12438b', datetime.datetime(2024, 8, 23, 15, 58, 0, 352245), datetime.datetime(2024, 8, 23, 15, 58, 0, 352245), None)\n",
      "(\"I don't know.\", '', 'CHATBOT', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 2, True, 'd9da10a4-2048-431d-9f5b-6644834f8a01', datetime.datetime(2024, 8, 23, 15, 58, 6, 765530), datetime.datetime(2024, 8, 23, 15, 58, 6, 765530), None)\n",
      "('What is the recruitment process at Tech Innovator Inc?', None, 'USER', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 3, True, 'd7152962-c8b0-4012-afe9-5e04ac4f763a', datetime.datetime(2024, 8, 23, 16, 44, 42, 897640), datetime.datetime(2024, 8, 23, 16, 44, 42, 897640), None)\n",
      "(\"I don't have information about the specific recruitment process at Tech Innovator Inc.\", '', 'CHATBOT', '5e5eb1fb-2df0-4b1b-99be-cc9af6768791', '0b0881f8-e945-4c5d-9da2-58c0ade75855', 3, True, '77f6a754-f720-4f0b-a6d6-0c5384155dc6', datetime.datetime(2024, 8, 23, 16, 44, 46, 165888), datetime.datetime(2024, 8, 23, 16, 44, 46, 165888), None)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a SQL query\n",
    "cur.execute(\"SELECT * FROM messages;\")\n",
    "\n",
    "# Fetch the results\n",
    "rows = cur.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Document\\GitHub\\cohere-rag-eval\\venv\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# pip install cohere numpy\n",
    "import numpy as np\n",
    "import cohere\n",
    "os.environ[\"COHERE_API_KEY\"] = os.getenv('COHERE_API_KEY')\n",
    "co = cohere.Client(api_key=os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the documents\n",
    "faqs_long = [\n",
    "    {\"text\": \"Joining Slack Channels: You will receive an invite via email. Be sure to join relevant channels to stay informed and engaged.\"},\n",
    "    {\"text\": \"Finding Coffee Spots: For your caffeine fix, head to the break room's coffee machine or cross the street to the café for artisan coffee.\"},\n",
    "    {\"text\": \"Team-Building Activities: We foster team spirit with monthly outings and weekly game nights. Feel free to suggest new activity ideas anytime!\"},\n",
    "    {\"text\": \"Working Hours Flexibility: We prioritize work-life balance. While our core hours are 9 AM to 5 PM, we offer flexibility to adjust as needed.\"},\n",
    "    {\"text\": \"Side Projects Policy: We encourage you to pursue your passions. Just be mindful of any potential conflicts of interest with our business.\"},\n",
    "    {\"text\": \"Reimbursing Travel Expenses: Easily manage your travel expenses by submitting them through our finance tool. Approvals are prompt and straightforward.\"},\n",
    "    {\"text\": \"Working from Abroad: Working remotely from another country is possible. Simply coordinate with your manager and ensure your availability during core hours.\"},\n",
    "    {\"text\": \"Health and Wellness Benefits: We care about your well-being and offer gym memberships, on-site yoga classes, and comprehensive health insurance.\"},\n",
    "    {\"text\": \"Performance Reviews Frequency: We conduct informal check-ins every quarter and formal performance reviews twice a year.\"},\n",
    "    {\"text\": \"Proposing New Ideas: Innovation is welcomed! Share your brilliant ideas at our weekly team meetings or directly with your team lead.\"},\n",
    "]\n",
    "\n",
    "# Embed the documents\n",
    "doc_emb = co.embed(\n",
    "            model=\"embed-english-v3.0\",\n",
    "            input_type=\"search_document\",\n",
    "            texts=[doc['text'] for doc in faqs_long]).embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the user query\n",
    "query = \"How to get to know my teammates\"\n",
    "# Generate the search query\n",
    "response = co.chat(message=query,\n",
    "                  search_queries_only=True)\n",
    "query_optimized = response.search_queries[0].text\n",
    "# Embed the search query\n",
    "query_emb = co.embed(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    input_type=\"search_query\",\n",
    "    texts=[query_optimized]).embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n",
      "Score: 0.32653470360872655\n",
      "Document: {'text': 'Team-Building Activities: We foster team spirit with monthly outings and weekly game nights. Feel free to suggest new activity ideas anytime!'}\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.2685185535226478\n",
      "Document: {'text': 'Proposing New Ideas: Innovation is welcomed! Share your brilliant ideas at our weekly team meetings or directly with your team lead.'}\n",
      "\n",
      "Rank: 3\n",
      "Score: 0.2581341975304149\n",
      "Document: {'text': 'Joining Slack Channels: You will receive an invite via email. Be sure to join relevant channels to stay informed and engaged.'}\n",
      "\n",
      "Rank: 4\n",
      "Score: 0.18633336738178458\n",
      "Document: {'text': \"Finding Coffee Spots: For your caffeine fix, head to the break room's coffee machine or cross the street to the café for artisan coffee.\"}\n",
      "\n",
      "Rank: 5\n",
      "Score: 0.13022396595682817\n",
      "Document: {'text': 'Health and Wellness Benefits: We care about your well-being and offer gym memberships, on-site yoga classes, and comprehensive health insurance.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute dot product similarity and display results\n",
    "n = 5\n",
    "scores = np.dot(query_emb, np.transpose(doc_emb))[0]\n",
    "scores_sorted = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:n]\n",
    "retrieved_documents = [faqs_long[item[0]] for item in scores_sorted]\n",
    "for idx, item in enumerate(scores_sorted):\n",
    "    print(f\"Rank: {idx+1}\")\n",
    "    print(f\"Score: {item[1]}\")\n",
    "    print(f\"Document: {faqs_long[item[0]]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n",
      "Score: 0.0040072887\n",
      "Document: {'text': 'Joining Slack Channels: You will receive an invite via email. Be sure to join relevant channels to stay informed and engaged.'}\n",
      "\n",
      "Rank: 2\n",
      "Score: 0.0020829707\n",
      "Document: {'text': 'Team-Building Activities: We foster team spirit with monthly outings and weekly game nights. Feel free to suggest new activity ideas anytime!'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rerank the documents\n",
    "results = co.rerank(query=query_optimized,\n",
    "                    documents=retrieved_documents,\n",
    "                    top_n=2,\n",
    "                    model='rerank-english-v3.0')\n",
    "\n",
    "# Display the reranking results\n",
    "for idx, result in enumerate(results.results):\n",
    "    print(f\"Rank: {idx+1}\") \n",
    "    print(f\"Score: {result.relevance_score}\")\n",
    "    print(f\"Document: {retrieved_documents[result.index]}\\n\")\n",
    "    \n",
    "reranked_documents = [retrieved_documents[result.index] for result in results.results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting to know your teammates can be done in a variety of ways. You could join your company's Slack channels to stay informed and connected. You could also take part in team-building activities such as outings and game nights.\n",
      "\n",
      "CITATIONS:\n",
      "start=75 end=109 text=\"join your company's Slack channels\" document_ids=['doc_0']\n",
      "start=113 end=141 text='stay informed and connected.' document_ids=['doc_0']\n",
      "start=170 end=194 text='team-building activities' document_ids=['doc_1']\n",
      "start=203 end=227 text='outings and game nights.' document_ids=['doc_1']\n",
      "\n",
      "DOCUMENTS:\n",
      "{'id': 'doc_0', 'text': 'Joining Slack Channels: You will receive an invite via email. Be sure to join relevant channels to stay informed and engaged.'}\n",
      "{'id': 'doc_1', 'text': 'Team-Building Activities: We foster team spirit with monthly outings and weekly game nights. Feel free to suggest new activity ideas anytime!'}\n"
     ]
    }
   ],
   "source": [
    "# Generate the response\n",
    "response = co.chat(\n",
    "                message=query_optimized,\n",
    "                model=\"command-r-plus\",\n",
    "                documents=reranked_documents)\n",
    "\n",
    "# Display the response\n",
    "print(response.text)\n",
    "\n",
    "# Display the citations and source documents\n",
    "if response.citations:\n",
    "  print(\"\\nCITATIONS:\")\n",
    "  for citation in response.citations:\n",
    "    print(citation)\n",
    "\n",
    "  print(\"\\nDOCUMENTS:\")\n",
    "  for document in response.documents:\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Conversation Data to HuggingFace Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {\n",
    "    'question':[[query]],\n",
    "    'answer':[[response.text]],\n",
    "    'contexts':[[\"\\n\".join([document[\"text\"] for document in response.documents])]],\n",
    "    'ground_truth':[['true']]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': [['How to get to know my teammates']],\n",
       " 'answer': [[\"Getting to know your teammates can be done in a variety of ways. You could join your company's Slack channels to stay informed and connected. You could also take part in team-building activities such as outings and game nights.\"]],\n",
       " 'contexts': [['Joining Slack Channels: You will receive an invite via email. Be sure to join relevant channels to stay informed and engaged.\\nTeam-Building Activities: We foster team spirit with monthly outings and weekly game nights. Feel free to suggest new activity ideas anytime!']],\n",
       " 'ground_truth': [['true']]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "# Define features with variable length for \"answer\"\n",
    "#features = {'question': str, 'answer': Dataset.Variable(dtype=str), 'contexts': [Dataset.Feature({'id': str, 'text': str})]}\n",
    "\n",
    "# Create the dataset with the features\n",
    "dataset = Dataset.from_dict(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with RAGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Document\\GitHub\\cohere-rag-eval\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 5599.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define LLM\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.environ[\"GROD_CLOUD_API_KEY\"],\n",
    "    model_name='llama-3.1-8b-instant'\n",
    "    )\n",
    "\n",
    "#Define Enbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "fastembed_embeddings = FastEmbedEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset feature \"question\" should be of type string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseLanguageModel\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[1;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#context_precision,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext_recall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfaithfulness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer_relevancy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfastembed_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#run_config=RunConfig(max_workers=2),\u001b[39;49;00m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m df \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[1;32md:\\Document\\GitHub\\cohere-rag-eval\\venv\\Lib\\site-packages\\ragas\\_analytics.py:129\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m    128\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\Document\\GitHub\\cohere-rag-eval\\venv\\Lib\\site-packages\\ragas\\evaluation.py:165\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, run_config, token_usage_parser, raise_exceptions, column_map)\u001b[0m\n\u001b[0;32m    163\u001b[0m dataset \u001b[38;5;241m=\u001b[39m handle_deprecated_ground_truths(dataset)\n\u001b[0;32m    164\u001b[0m validate_evaluation_modes(dataset, metrics)\n\u001b[1;32m--> 165\u001b[0m \u001b[43mvalidate_column_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# set the llm and embeddings\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm, LangchainLLM):\n",
      "File \u001b[1;32md:\\Document\\GitHub\\cohere-rag-eval\\venv\\Lib\\site-packages\\ragas\\validation.py:46\u001b[0m, in \u001b[0;36mvalidate_column_dtypes\u001b[1;34m(ds)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_names \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mfeatures[column_names]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 46\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     47\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m should be of type string\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     48\u001b[0m             )\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_names \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontexts\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m column_names \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mfeatures:\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset feature \"question\" should be of type string"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_utilization,\n",
    ")\n",
    "\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=[\n",
    "        #context_precision,\n",
    "        context_utilization,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "    ],\n",
    "    llm=llm,\n",
    "    embeddings=fastembed_embeddings, \n",
    "    #run_config=RunConfig(max_workers=2),\n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
