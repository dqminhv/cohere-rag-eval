{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the .env file\n",
    "#pip install -U python-dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohere container's backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_rag_get_answers(message):\n",
    "   import requests\n",
    "   import cohere\n",
    "   import json\n",
    "   import os\n",
    "   os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "   # Define the API endpoint for streaming\n",
    "   url = \"http://localhost:8000/v1/chat\"\n",
    "   # bearer = os.getenv('BEARER_SECRET_KEY')\n",
    "   bearer = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJjb2hlcmUtdG9vbGtpdCIsImlhdCI6MTcyNjE4MDM0MywiZXhwIjoxNzMzOTU2MzQzLCJqdGkiOiJiNjUzYmYwZS0wNzMxLTQzYmYtYjk0Ni1jYjgxNmJkYjg2ZWUiLCJjb250ZXh0Ijp7ImlkIjoiZWE5MjBhZDYtYjc1My00OGFlLTkxZGEtZWM0MjMzZTI0ZjBlIiwiZnVsbG5hbWUiOiJNaW5oIER1b25nIiwiZW1haWwiOiJkcW1pbmh2QGdtYWlsLmNvbSJ9fQ.vkrj7NH2mb8SvzQtIlYoQwcLXuGdixk_NuNtPA59p7w\"\n",
    "\n",
    "   # Set headers\n",
    "   headers = {\n",
    "       \"User-Id\": \"me\",\n",
    "       \"Content-Type\": \"application/json\",\n",
    "       \"Authorization\": f\"Bearer {bearer}\",\n",
    "       \"Cohere-Stream\": \"true\",  # Enable streaming for chatbot responses\n",
    "   }\n",
    "\n",
    "   # Create the payload as a JSON dictionary\n",
    "   data = {\"message\": message}\n",
    "\n",
    "   # Send the POST request using requests\n",
    "   response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "   # Check for successful response\n",
    "   if response.status_code == 200:\n",
    "     # Handle streaming response\n",
    "     for line in response.iter_lines():\n",
    "       # Decode the response (if necessary)\n",
    "       decoded_line = line.decode(\"utf-8\")\n",
    "       # Process the received data from the stream (print it here)\n",
    "       response_data = json.loads(decoded_line)  # Parse the JSON string\n",
    "       #print(decoded_line)\n",
    "       return {\n",
    "      'answer': response_data.get(\"text\"),\n",
    "      'contexts': response_data.get(\"documents\")\n",
    "      }\n",
    "   else:\n",
    "     print(f\"Error: {response.status_code}\")\n",
    "     return {\n",
    "       'answer': \"Error: {response.status_code}\",\n",
    "      'contexts': []\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Sorry, I am unable to access real-time information on the tickets created at Tech Innovator Inc. However, based on the context provided earlier, it appears that the company uses a ticketing system to track employee tasks and projects. The tickets are likely related to various technical issues, inquiries, or assignments that employees need to address or work on. These tickets are probably created as part of their workflow management and help desk functions. \\n\\nTech Innovator Inc. seems to be an imaginative and forward-thinking organization, so the ticketing system might be digitally based, with efficient categorization and prioritization procedures to ensure that each ticket is addressed in a timely manner. However, without further information, I can only speculate about the specific nature and processes involved in the tickets created within the company.',\n",
       " 'contexts': []}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohere_rag_get_answers(\"What are the tickets created at Tech Innovator Inc?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohere postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2 \n",
    "import sqlalchemy \n",
    "from sqlalchemy import MetaData, text \n",
    "\n",
    "#from backend.config.settings import Settings \n",
    "from sqlalchemy import create_engine \n",
    "import pandas as pd \n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection is Engine(postgresql+psycopg2://postgres:***@localhost:5432)\n",
      "2024-09-12 15:35:25,915 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2024-09-12 15:35:25,916 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-09-12 15:35:25,920 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2024-09-12 15:35:25,920 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-09-12 15:35:25,923 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2024-09-12 15:35:25,923 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2024-09-12 15:35:25,926 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-09-12 15:35:25,926 INFO sqlalchemy.engine.Engine SELECT * FROM conversations;\n",
      "2024-09-12 15:35:25,926 INFO sqlalchemy.engine.Engine [generated in 0.00104s] {}\n",
      "2024-09-12 15:35:25,930 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "DATABASE_URL = 'postgresql+psycopg2://postgres:postgres@localhost:5432' \n",
    "\n",
    "engine = sqlalchemy.create_engine(DATABASE_URL, echo=True) \n",
    " \n",
    "print(\"Connection is\", engine) \n",
    " \n",
    "# Execute a raw SQL query to get data from chat conversations \n",
    "with engine.connect() as connection: \n",
    "    query = \"SELECT * FROM conversations;\" \n",
    "    result = connection.execute(text(query)) \n",
    "    rows = [row for row in result] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                user_id                         title  \\\n",
      "0  ea920ad6-b753-48ae-91da-ec4233e24f0e  What are the tickets created   \n",
      "1  ea920ad6-b753-48ae-91da-ec4233e24f0e  What are the tickets created   \n",
      "2  ea920ad6-b753-48ae-91da-ec4233e24f0e  What are the tickets created   \n",
      "3  ea920ad6-b753-48ae-91da-ec4233e24f0e      What steps are needed to   \n",
      "4  ea920ad6-b753-48ae-91da-ec4233e24f0e  What are the tickets created   \n",
      "\n",
      "                                         description  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3  To extract data from Confluence and create a R...   \n",
      "4  Sorry, I am unable to access real-time informa...   \n",
      "\n",
      "                                     id                 created_at  \\\n",
      "0  6ae650ce-1f22-4430-8d99-59bb0f2a7ced 2024-09-12 21:43:25.251956   \n",
      "1  cde92994-d692-406f-bc92-f0d5197fec6a 2024-09-12 21:44:01.242650   \n",
      "2  4bd6e616-e689-4cd7-96ad-e44692d0ac6e 2024-09-12 21:48:04.771031   \n",
      "3  21fbaa26-ea0d-42b2-854e-f33a1bfd10c6 2024-09-12 21:50:03.788931   \n",
      "4  d17c880e-611f-4557-8041-0bd7df73b807 2024-09-12 21:50:54.488157   \n",
      "\n",
      "                  updated_at agent_id organization_id  \n",
      "0 2024-09-12 21:43:35.445968     None            None  \n",
      "1 2024-09-12 21:44:09.638771     None            None  \n",
      "2 2024-09-12 21:48:12.484497     None            None  \n",
      "3 2024-09-12 21:50:09.614430     None            None  \n",
      "4 2024-09-12 21:50:56.136357     None            None  \n"
     ]
    }
   ],
   "source": [
    "# Assign the appropriate column names \n",
    "column_names = ['user_id', 'title', 'description', 'id', 'created_at', \n",
    "'updated_at', 'agent_id', 'organization_id'] \n",
    " \n",
    "# Create a DataFrame \n",
    "df = pd.DataFrame(rows, columns=column_names) \n",
    " \n",
    "# Print the DataFrame \n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agent_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>organization_id</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [user_id, title, description, id, created_at, updated_at, agent_id, organization_id]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   USER                                           QUESTION  CHATBOT  \\\n",
      "0  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "1  USER  \"What are the tickets created at Tech Innovato...  CHATBOT   \n",
      "2  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "3  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "4  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "5  USER  What steps are needed to extract data from Con...  CHATBOT   \n",
      "6  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "7  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "8  USER  What are the tickets created at Tech Innovator...  CHATBOT   \n",
      "\n",
      "                                            RESPONSE  \\\n",
      "0  Sorry, I am unable to access real-time informa...   \n",
      "1                                                      \n",
      "2  Sorry, I could not find any specific informati...   \n",
      "3  Sorry, I am unable to access real-time informa...   \n",
      "4  Sorry, I am unable to access real-time informa...   \n",
      "5  To extract data from Confluence and create a R...   \n",
      "6                                                      \n",
      "7                                                      \n",
      "8                                                      \n",
      "\n",
      "                             MESSAGE_ID  DOCUMENTS  \n",
      "0  bc340af9-4779-48a4-9af5-dd3e86ff4d6f        NaN  \n",
      "1  063ea55a-2af2-44d5-80e6-470cdcf99ea1        NaN  \n",
      "2  2ce8f27f-e105-4bc0-86e5-90286df02f1f        NaN  \n",
      "3  5ae60f49-b6b4-4153-824f-1cd454b50040        NaN  \n",
      "4  6401b624-b192-4ddc-aa45-b681bc86143b        NaN  \n",
      "5  d31f9e41-d2f1-45f4-be2d-2b2555367a58        NaN  \n",
      "6  1453cb8c-afb0-489b-a16c-3b18f5d06190        NaN  \n",
      "7  265dbc22-12ca-4e17-8248-4cab25a177c7        NaN  \n",
      "8  beaa9b45-5720-4987-a2ef-edf4dc0edd4a        NaN  \n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy import MetaData, text\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATABASE_URL = 'postgresql+psycopg2://postgres:postgres@localhost:5432'\n",
    "\n",
    "engine = sqlalchemy.create_engine(DATABASE_URL, echo=True)\n",
    "\n",
    "# print(\"Connection is\", engine)\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "create_view = \"\"\"\n",
    "                    CREATE OR REPLACE VIEW v_user_messages\n",
    "                    AS\n",
    "                    SELECT text, agent, conversation_id, created_at, id, tool_plan FROM messages \n",
    "                    WHERE agent = 'USER'\n",
    "                    ORDER BY created_at desc;\n",
    "\"\"\"\n",
    "# Execute the SQL query\n",
    "cur.execute(create_view)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "create_view = \"\"\"\n",
    "                    CREATE OR REPLACE VIEW v_chatbot_messages\n",
    "                    AS\n",
    "                    SELECT text, agent, conversation_id, created_at, id, tool_plan FROM messages \n",
    "                    WHERE agent = 'CHATBOT'\n",
    "                    ORDER BY created_at desc;\n",
    "\"\"\"\n",
    "# Execute the SQL query\n",
    "cur.execute(create_view)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Get the questions and corresponding answers\n",
    "query = \"\"\"SELECT \n",
    "            user_msgs.agent, \n",
    "            user_msgs.text,\n",
    "            chatbot_msgs.agent, \n",
    "            chatbot_msgs.text,\n",
    "            chatbot_msgs.id\n",
    "        FROM public.v_user_messages as user_msgs\n",
    "        INNER JOIN public.v_chatbot_messages as chatbot_msgs\n",
    "        ON\n",
    "            user_msgs.conversation_id = chatbot_msgs.conversation_id\n",
    "        WHERE\n",
    "            chatbot_msgs.tool_plan IS NULL\n",
    "        ORDER BY user_msgs.created_at desc;\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "cur.execute(query)\n",
    "\n",
    "# Fetch all results from the executed query\n",
    "result = cur.fetchall()\n",
    "rows = [row for row in result]\n",
    "\n",
    "\n",
    "# Assign the appropriate column names\n",
    "column_names = ['USER', 'QUESTION', 'CHATBOT', 'RESPONSE', 'MESSAGE_ID']\n",
    "\n",
    "# Create a DataFrame\n",
    "df_messages = pd.DataFrame(rows, columns=column_names)\n",
    "\n",
    "# Fetch the context for the response if present\n",
    "query_documents = \"\"\"SELECT text, conversation_id, message_id, document_id \n",
    "        FROM public.documents\n",
    "            ;\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "cur.execute(query_documents)\n",
    "\n",
    "# Fetch all results from the executed query\n",
    "doc_result = cur.fetchall()\n",
    "doc_rows = [row for row in doc_result]\n",
    "\n",
    "# Assign the appropriate column names\n",
    "doc_column_names = ['TEXT', 'CONVERSATION_ID', 'MESSAGE_ID', 'DOCUMENT_ID']\n",
    "\n",
    "# Create a DataFrame\n",
    "df_documents = pd.DataFrame(doc_rows, columns=doc_column_names)\n",
    "\n",
    "# Get unique message ids from documents dataframe\n",
    "unique_message_ids = df_documents['MESSAGE_ID'].unique()\n",
    "\n",
    "messages = list(unique_message_ids)\n",
    "documents = []\n",
    "for message_id in unique_message_ids:\n",
    "    # Filter documents for the current message id\n",
    "    df_doc_filtered = list(df_documents[df_documents.MESSAGE_ID == message_id]['TEXT'].values)\n",
    "    # Concatenate the text from the documents into a single string\n",
    "    documents.append(df_doc_filtered)\n",
    "\n",
    "df_message_documents = pd.DataFrame(\n",
    "    {\n",
    "        'MESSAGE_ID': messages,\n",
    "        'DOCUMENTS': documents\n",
    "    }\n",
    ")\n",
    "\n",
    "# Join the dataframes to attach documents to the messages\n",
    "df_messages_with_documents = pd.merge(df_messages, df_message_documents, on='MESSAGE_ID', how='left')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_messages_with_documents)\n",
    "df_messages_with_documents[['QUESTION', 'RESPONSE', 'DOCUMENTS']].to_csv(\"messages.csv\", index=False)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
