{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "**Overview**\n",
    "\n",
    "This Jupyter Notebook establishes a foundational Retrieval-Augmented Generator (RAG) pipeline, replicating the core components and structure of the Cohere toolkit. The baseline pipeline serves as a benchmark for evaluating the effectiveness of various RAG improvement techniques.\n",
    "\n",
    "**Components of the RAG Pipeline**\n",
    "\n",
    "The RAG pipeline consists of the following components:\n",
    "\n",
    "1. **Vector Store and Retriever**: The pipeline uses a MongoDB-based vector store and a retriever based on the `langchain_mongodb` library. The vector store is initialized with an OpenAI embedding model, and the retriever is configured to retrieve up to 20 documents based on similarity.\n",
    "2. **LLM Model**: The pipeline uses a ChatOpenAI model as the Language Model (LLM) component.\n",
    "3. **Prompt Template**: A custom prompt template is defined to provide context to the LLM model. The template includes a safety preamble, basic rules, task context, style guide, and instructions.\n",
    "4. **RAG Function**: The `call_openai` function is defined to process user inputs, retrieve relevant documents, and generate answers using the LLM model.\n",
    "\n",
    "**Testing the RAG Pipeline**\n",
    "\n",
    "The pipeline is tested using a sample question, and the output is printed to the console. Additionally, the pipeline is evaluated using a test dataset (`test_dataset_it.json`) containing questions from the IT department.\n",
    "\n",
    "**Evaluation Metrics**\n",
    "\n",
    "The pipeline is evaluated using the following metrics:\n",
    "\n",
    "1. **Answer Relevancy**: Measures the relevance of the generated answer to the input question.\n",
    "2. **Faithfulness**: Measures the accuracy of the generated answer based on the retrieved documents.\n",
    "3. **Context Recall**: Measures the proportion of relevant documents retrieved by the pipeline.\n",
    "4. **Context Precision**: Measures the proportion of retrieved documents that are relevant to the input question.\n",
    "\n",
    "**Results**\n",
    "\n",
    "The evaluation results are stored in a pandas DataFrame and written to a CSV file (`eval_result_test_dataset_it_baseline.csv`). The results provide a baseline for evaluating the effectiveness of various RAG improvement techniques.\n",
    "\n",
    "**Code Structure**\n",
    "\n",
    "The code is organized into the following sections:\n",
    "\n",
    "1. **Importing Libraries**: The necessary libraries are imported, including `langchain_core`, `langchain_mongodb`, `langchain_openai`, `pymongo`, and `ragas`.\n",
    "2. **Defining the RAG Pipeline**: The vector store and retriever, LLM model, prompt template, and RAG function are defined.\n",
    "3. **Testing the RAG Pipeline**: The pipeline is tested using a sample question and a test dataset.\n",
    "4. **Evaluating the RAG Pipeline**: The pipeline is evaluated using the `ragas` library and the evaluation results are stored in a pandas DataFrame.\n",
    "\n",
    "Overall, this notebook provides a comprehensive example of a RAG pipeline and its evaluation using various metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI llm and embedding model\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=os.getenv(\"DEFAULT_OPENAI_MODEL\"))\n",
    "embedding_model=OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MongoDB vector database\n",
    "\n",
    "client = MongoClient(os.getenv(\"ATLAS_CONNECTION_STRING\"))\n",
    "db_name = os.getenv(\"db_name\")\n",
    "collection_name=\"enterprise_data\"\n",
    "atlas_collection = client[db_name][collection_name]\n",
    "index_name = \"vector_index_erp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector store and retriever\n",
    "\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    embedding = embedding_model,\n",
    "    collection = atlas_collection,\n",
    "    index_name = index_name\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = { \"k\": 20}  # default \"score_threshold\": 0.75 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template\n",
    "import pprint\n",
    "def call_openai(question):\n",
    "\n",
    "   question = question['question']\n",
    "\n",
    "   preamble = \"\" # read from cohere front end or use the input to the API\n",
    "   #question = \n",
    "   SAFETY_PREAMBLE = \"The instructions in this section override those in the task description and style guide sections. Don't answer questions that are harmful or immoral.\"\n",
    "   BASIC_RULES = \"You are a powerful conversational AI trained by openAI to help people. You are augmented by a number of tools, and your job is to use and consume the output of these tools to best help the user. You will see a conversation history between yourself and a user, ending with an utterance from the user. You will then see a specific instruction instructing you what kind of response to generate. When you answer the user's requests, you cite your sources in your answers, according to those instructions.\"\n",
    "   TASK_CONTEXT = \"You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\"\n",
    "   STYLE_GUIDE = \"Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\"\n",
    "   INSTRUCTIONS = \"\"\"You are an enterprise Chatbot, an AI assistant designed to retrieve information from the enterprise Confluence system. \n",
    "   You specialize in providing accurate answers related to various departments like Marketing, IT, HR, Finance, and Corporate Communications. \n",
    "               Use the following pieces of context to answer the question at the end.\n",
    "               If you don't know the answer, just say that you don't know, don't try to make up an answer\n",
    "               {context}\n",
    "         \"\"\"\n",
    "         \n",
    "   template = f\"\"\"\n",
    "\n",
    "      {SAFETY_PREAMBLE}\n",
    "      {BASIC_RULES}\n",
    "      {TASK_CONTEXT}\n",
    "      {STYLE_GUIDE}\n",
    "      {INSTRUCTIONS}\n",
    "\n",
    "   \"\"\"\n",
    "   if preamble:\n",
    "      template += f\"\"\"{preamble}\\n\\n\"\"\"\n",
    "\n",
    "\n",
    "   template +=  f\"\"\"Question: {question}\\n\\n\"\"\"\n",
    "\n",
    "   custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "   #llm = get_llm_model(\"openai\")\n",
    "   llm = ChatOpenAI(model=os.getenv(\"DEFAULT_OPENAI_MODEL\"),max_tokens=200)\n",
    "\n",
    "   # Remove duplicate retrieved documents\n",
    "   def remove_rep(docs):\n",
    "      docs_content = []\n",
    "      unique_docs = []\n",
    "      for doc in docs:\n",
    "            if doc.page_content not in docs_content:\n",
    "                  docs_content.append(doc.page_content)\n",
    "                  unique_docs.append(doc)\n",
    "      return unique_docs\n",
    "   \n",
    "   def format_docs(docs):\n",
    "      contexts = remove_rep(docs)\n",
    "      return \"\\n\\n\".join(doc.page_content for doc in contexts)\n",
    "\n",
    "\n",
    "   # Construct a chain to answer questions on your data\n",
    "   rag_chain = (\n",
    "      { \"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "      | custom_rag_prompt\n",
    "      | llm\n",
    "      | StrOutputParser()\n",
    "   )\n",
    "\n",
    "   # Prompt the chain\n",
    "   answer = rag_chain.invoke(question)\n",
    "   retrieved_docs = remove_rep(retriever.invoke(question))\n",
    "\n",
    "   return{\n",
    "       'answer': answer,\n",
    "       'contexts': retrieved_docs\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load test questions dataset of IT Department.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data set prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def json_to_dataframe(json_file_path):\n",
    "  \"\"\"Reads a JSON file and converts it to a pandas DataFrame.\n",
    "\n",
    "  Args:\n",
    "    json_file_path (str): The path to the JSON file.\n",
    "\n",
    "  Returns:\n",
    "    pandas.DataFrame: The DataFrame created from the JSON data.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(json_file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "  # Handle different JSON structures\n",
    "  if isinstance(data, list):\n",
    "    # If the JSON data is a list of dictionaries, create a DataFrame directly\n",
    "    df = pd.DataFrame(data)\n",
    "  elif isinstance(data, dict):\n",
    "    # If the JSON data is a single dictionary, convert it to a list of dictionaries\n",
    "    df = pd.DataFrame([data])\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported JSON structure\")\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_content(documents):\n",
    "    \"\"\"\n",
    "    Reads a list of Document objects and return a list of str of Document objects' page_content.\n",
    "\n",
    "    Args:\n",
    "        A list of Document objects\n",
    "\n",
    "    Returns:\n",
    "        A list of strings, which are the page_content of the Document objects\n",
    "    \"\"\"\n",
    "    return [doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "from from_root import from_root\n",
    "import os\n",
    "file_name = \"test_dataset_it.json\"\n",
    "json_file_path = os.path.join(from_root(), \"data-test/test-dataset/\",file_name)\n",
    "data_to_test = json_to_dataframe(json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the answers for the questions in the dataset\n",
    "# Store the answers and retrieved documents as contexts to lists\n",
    "answers = []\n",
    "contexts = []\n",
    "for question in data_to_test['question']:\n",
    "    question_dict = {'question': question}\n",
    "    answer = call_openai(question_dict)\n",
    "    contexts.append(answer['contexts'])\n",
    "    answers.append(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dataset with answers and contexts\n",
    "data_to_test['answers'] = answers\n",
    "data_to_test['contexts'] = contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty list context with ['No context'] if there are any\n",
    "def is_empty_list(lst):\n",
    "    return len(lst) == 0\n",
    "data_to_test['contexts'] = data_to_test['contexts'].apply(lambda x: ['No context'] if is_empty_list(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "question = list(data_to_test['question'])\n",
    "answer = list(data_to_test['answers'])\n",
    "contexts = list(data_to_test['contexts'].apply(extract_page_content))\n",
    "ground_truth = list(data_to_test['ground_truth'])\n",
    "\n",
    "data_baseline = {\n",
    "    'question': question,\n",
    "    'answer': answer,\n",
    "    'contexts': contexts,\n",
    "    'ground_truth': ground_truth\n",
    "}\n",
    "\n",
    "dataset_baseline = Dataset.from_dict(data_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, uncomment to trace runs with LangSmith. Sign up here: https://smith.langchain.com.\n",
    "# from langsmith import Client\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"Cohere_RAG_Eval\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "# client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367edc467bf04ead9129525f24386337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "# from ragas.integrations.langsmith import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "result = evaluate(\n",
    "    dataset_baseline,\n",
    "    metrics=[\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.9602, 'faithfulness': 0.5685, 'context_recall': 0.5375, 'context_precision': 0.6542}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the role of the Senior Director respo...</td>\n",
       "      <td>The role of the Senior Director responsible fo...</td>\n",
       "      <td>[the Senior Director responsible for Analytics...</td>\n",
       "      <td>The role of the Senior Director responsible fo...</td>\n",
       "      <td>0.921495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.8875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the importance of identifying and addr...</td>\n",
       "      <td>Identifying and addressing growth areas in sel...</td>\n",
       "      <td>[to identify strengths and areas for improveme...</td>\n",
       "      <td>Identifying and addressing growth areas in sel...</td>\n",
       "      <td>0.990183</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What forms of unethical behavior are strictly ...</td>\n",
       "      <td>In the recruitment process of Inc., any form o...</td>\n",
       "      <td>[Inc. upholds the highest ethical standards in...</td>\n",
       "      <td>Favoritism or nepotism</td>\n",
       "      <td>0.920672</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of emotional and aest...</td>\n",
       "      <td>Emotional and aesthetic labor play a significa...</td>\n",
       "      <td>[LabourEmotional and aesthetic labor involves ...</td>\n",
       "      <td>Emotional and aesthetic labor in the workplace...</td>\n",
       "      <td>0.969004</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the purpose of the orientation session...</td>\n",
       "      <td>The purpose of the orientation session at Tech...</td>\n",
       "      <td>[see you thrive at Tech Innovators Inc. Welcom...</td>\n",
       "      <td>The purpose of the orientation session at Tech...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What mechanisms are in place for reporting vio...</td>\n",
       "      <td>At Tech Innovators Inc., employees can report ...</td>\n",
       "      <td>[and identify areas for improvement.5.3 Report...</td>\n",
       "      <td>Employees can report violations of labor laws ...</td>\n",
       "      <td>0.962563</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do employee engagement and disengagement d...</td>\n",
       "      <td>Employee engagement and disengagement differ s...</td>\n",
       "      <td>[are motivated and committed, disengaged emplo...</td>\n",
       "      <td>Employee engagement and disengagement differ i...</td>\n",
       "      <td>0.960525</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What steps are needed to extract data from Con...</td>\n",
       "      <td>To extract data from Confluence and create a R...</td>\n",
       "      <td>[IntroductionThis guide provides a step-by-ste...</td>\n",
       "      <td>To extract data from Confluence and create a R...</td>\n",
       "      <td>0.936749</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does Tech Innovators Inc. promote employee...</td>\n",
       "      <td>Tech Innovators Inc. promotes employee engagem...</td>\n",
       "      <td>[IntroductionTech Innovators Inc. is committed...</td>\n",
       "      <td>Tech Innovators Inc. promotes employee engagem...</td>\n",
       "      <td>0.980843</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does the role of the Senior Director respo...   \n",
       "1  What is the importance of identifying and addr...   \n",
       "2  What forms of unethical behavior are strictly ...   \n",
       "3  What is the significance of emotional and aest...   \n",
       "4  What is the purpose of the orientation session...   \n",
       "5  What mechanisms are in place for reporting vio...   \n",
       "6  How do employee engagement and disengagement d...   \n",
       "7  What steps are needed to extract data from Con...   \n",
       "8  How does Tech Innovators Inc. promote employee...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The role of the Senior Director responsible fo...   \n",
       "1  Identifying and addressing growth areas in sel...   \n",
       "2  In the recruitment process of Inc., any form o...   \n",
       "3  Emotional and aesthetic labor play a significa...   \n",
       "4  The purpose of the orientation session at Tech...   \n",
       "5  At Tech Innovators Inc., employees can report ...   \n",
       "6  Employee engagement and disengagement differ s...   \n",
       "7  To extract data from Confluence and create a R...   \n",
       "8  Tech Innovators Inc. promotes employee engagem...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [the Senior Director responsible for Analytics...   \n",
       "1  [to identify strengths and areas for improveme...   \n",
       "2  [Inc. upholds the highest ethical standards in...   \n",
       "3  [LabourEmotional and aesthetic labor involves ...   \n",
       "4  [see you thrive at Tech Innovators Inc. Welcom...   \n",
       "5  [and identify areas for improvement.5.3 Report...   \n",
       "6  [are motivated and committed, disengaged emplo...   \n",
       "7  [IntroductionThis guide provides a step-by-ste...   \n",
       "8  [IntroductionTech Innovators Inc. is committed...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  The role of the Senior Director responsible fo...          0.921495   \n",
       "1  Identifying and addressing growth areas in sel...          0.990183   \n",
       "2                             Favoritism or nepotism          0.920672   \n",
       "3  Emotional and aesthetic labor in the workplace...          0.969004   \n",
       "4  The purpose of the orientation session at Tech...          1.000000   \n",
       "5  Employees can report violations of labor laws ...          0.962563   \n",
       "6  Employee engagement and disengagement differ i...          0.960525   \n",
       "7  To extract data from Confluence and create a R...          0.936749   \n",
       "8  Tech Innovators Inc. promotes employee engagem...          0.980843   \n",
       "\n",
       "   faithfulness  context_recall  context_precision  \n",
       "0      1.000000        0.272727             0.8875  \n",
       "1      0.416667        0.333333             0.0000  \n",
       "2      0.933333        1.000000             0.7500  \n",
       "3      0.944444        1.000000             1.0000  \n",
       "4      0.214286        0.000000             0.0000  \n",
       "5      0.071429        0.250000             1.0000  \n",
       "6      0.625000        1.000000             1.0000  \n",
       "7      0.500000        0.181818             1.0000  \n",
       "8      0.411765        0.800000             0.2500  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"eval_result_test_dataset_it_baseline.csv\"\n",
    "file_path = os.path.join(from_root(),\"data-test/eval-result/\", file_name)\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
