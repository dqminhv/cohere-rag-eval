{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dotenv.main:Python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pymongo import MongoClient\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_community.llms import Cohere\n",
    "from llama_index.postprocessor.flag_embedding_reranker import (\n",
    "    FlagEmbeddingReranker,\n",
    ")\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.postprocessor.rankgpt_rerank import RankGPTRerank\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# llm = ChatOpenAI(model=os.getenv(\"DEFAULT_OPENAI_MODEL\")) # DEFAULT_OPENAI_MODEL='gpt-4o-mini-2024-07-18'\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\") # DEFAULT_OPENAI_MODEL='gpt-4o-mini-2024-07-18'\n",
    "\n",
    "# embedding_model=OpenAIEmbeddings(model=os.getenv(\"DEFAULT_OPENAI_EMBEDDING\"), disallowed_special=())\n",
    "embedding_model=OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MongoDB vector database\n",
    "client = MongoClient(os.getenv(\"MONGO_DB_URL\"))\n",
    "db_name = \"fellowshipai\"\n",
    "collection_name = \"enterprise_data_2\"\n",
    "atlas_collection = client[db_name][collection_name]\n",
    "index_name = \"vector_index_erp_2\"\n",
    "compression_retriever_model = \"cohere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vector store and retriever\n",
    "def get_vector_store_retriver(index_name, embedding_model, collection):\n",
    "\n",
    "  vector_store = MongoDBAtlasVectorSearch(\n",
    "      embedding = embedding_model,\n",
    "      collection = atlas_collection,\n",
    "      index_name = index_name\n",
    "  )\n",
    "\n",
    "  retriever = vector_store.as_retriever(\n",
    "      search_type = \"similarity\",\n",
    "      search_kwargs = { \"k\": 10}  # \"score_threshold\": 0.75 \n",
    "  )\n",
    "\n",
    "  return(vector_store, retriever)\n",
    "\n",
    "vector_store, retriever = get_vector_store_retriver(index_name, embedding_model, atlas_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Atlas Vector Search as a retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = \"similarity\",\n",
    "    search_kwargs = { \"k\": 10  }\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the compressed retriever\n",
    "from FlagEmbedding import FlagLLMReranker\n",
    "from flashrank import Ranker, RerankRequest\n",
    "def get_compressed_retriever(model_name):\n",
    "    if model_name == \"cohere\":\n",
    "        compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    "        )\n",
    "    \n",
    "    if model_name == \"crossEncoderReranker\":\n",
    "        model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-base\")\n",
    "        compressor = CrossEncoderReranker(model=model, top_n=3)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "            base_compressor=compressor, base_retriever=retriever\n",
    "        )\n",
    "    \n",
    "    if model_name == \"gptCompressor\":\n",
    "        llm = ChatOpenAI(temperature=0, model='gpt-4')\n",
    "        compressor = LLMChainExtractor.from_llm(llm)\n",
    "        compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor, base_retriever=retriever\n",
    "        )\n",
    "\n",
    "    return compression_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to ensuring the security and integrity of its on-premise systems. This security policy outlines the measures and procedures to protect these systems from unauthorized access, data breaches, and other security threats. This policy applies to all\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "by:Jhon Watch, Chief Information Security Officer20/07/2024Effective Date:20/07/2024Tech Innovators Inc.#12, IT parkTech city, Tech state\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "by:Jhon Watch, Chief Information Security Officer20/07/2024Effective Date:20/07/2024Tech Innovators Inc.#12, IT parkTech city, Tech state\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "This policy applies to all employees, contractors, and third-party vendors who interact with Tech Innovators Inc.'s on-premise systems.ScopeThis policy covers all on-premise systems, including but not limited to:ServersNetwork devices (routers, switches, firewalls)WorkstationsStorage devicesBackup\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 5:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to protecting the confidentiality, integrity, and availability of its data and resources hosted on Microsoft Azure. This security policy outlines the measures and procedures to ensure the secure deployment, management, and usage of Azure services. This\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 6:\n",
      "\n",
      "Ticket ID: TI-67890Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: Emily ClarkDepartment: SalesLocation: United StatesEmail: emily.clark@techinnovators.comPhone: (555) 987-6543Issue SummaryTitle: Unable to access CRM systemDescriptionEmily Clark reported that she is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 7:\n",
      "\n",
      "usage of Azure services. This policy applies to all employees, contractors, and third-party vendors who interact with Tech Innovators Inc.'s Azure cloud services.ScopeThis policy covers all Azure services utilized by Tech Innovators Inc., including but not limited to:Azure Virtual Machines\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 8:\n",
      "\n",
      "Ticket ID: IT-12345Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: John DoeDepartment: MarketingEmail: john.doe@example.comPhone: (555) 123-4567Issue SummaryTitle: Unable to access the Marketing databaseDescriptionJohn Doe reported that he is unable to access the\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 9:\n",
      "\n",
      "steps.Check the log files located in /var/log/vector_db/ for error messages.ConclusionYou have successfully installed and configured the Tech Innovator Vector Database. You can now start using it for your applications.For more information, visit the official documentation.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 10:\n",
      "\n",
      "Confirmation:Created by: IT Support TeamLast Updated by: Jane Smith on July 20, 2024, 11:00 AM\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the tickets logged at tech innovators inc?\"\n",
    "docs = retriever.invoke(query)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Ticket ID: TI-67890Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: Emily ClarkDepartment: SalesLocation: United StatesEmail: emily.clark@techinnovators.comPhone: (555) 987-6543Issue SummaryTitle: Unable to access CRM systemDescriptionEmily Clark reported that she is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to ensuring the security and integrity of its on-premise systems. This security policy outlines the measures and procedures to protect these systems from unauthorized access, data breaches, and other security threats. This policy applies to all\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to protecting the confidentiality, integrity, and availability of its data and resources hosted on Microsoft Azure. This security policy outlines the measures and procedures to ensure the secure deployment, management, and usage of Azure services. This\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = get_compressed_retriever(\"cohere\")\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What are the tickets logged at tech innovators inc?\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Vadi\\.cache\\huggingface\\hub\\models--BAAI--bge-reranker-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cpu\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:04<00:00,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Ticket ID: TI-67890Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: Emily ClarkDepartment: SalesLocation: United StatesEmail: emily.clark@techinnovators.comPhone: (555) 987-6543Issue SummaryTitle: Unable to access CRM systemDescriptionEmily Clark reported that she is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to ensuring the security and integrity of its on-premise systems. This security policy outlines the measures and procedures to protect these systems from unauthorized access, data breaches, and other security threats. This policy applies to all\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "IntroductionTech Innovators Inc. is committed to protecting the confidentiality, integrity, and availability of its data and resources hosted on Microsoft Azure. This security policy outlines the measures and procedures to ensure the secure deployment, management, and usage of Azure services. This\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = get_compressed_retriever(\"crossEncoderReranker\")\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What are the tickets logged at tech innovators inc?\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vadi\\anaconda3\\envs\\toolkit\\Lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Ticket ID: TI-67890Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: Emily ClarkDepartment: SalesLocation: United StatesEmail: emily.clark@techinnovators.comPhone: (555) 987-6543Issue SummaryTitle: Unable to access CRM systemDescriptionEmily Clark reported that she is\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Ticket ID: IT-12345Created Date: July 20, 2024Priority: HighStatus: OpenRequester InformationName: John DoeDepartment: MarketingEmail: john.doe@example.comPhone: (555) 123-4567Issue SummaryTitle: Unable to access the Marketing databaseDescriptionJohn Doe reported that he is unable to access the\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = get_compressed_retriever(\"gptCompressor\")\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What are the tickets logged at tech innovators inc?\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cohere'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt template\n",
    "import pprint\n",
    "def call_openai(question):\n",
    "\n",
    "   question = question['question']\n",
    "\n",
    "   retriever = vector_store.as_retriever(\n",
    "      search_type = \"similarity\",\n",
    "      search_kwargs = { \"k\": 10  }\n",
    "      )\n",
    "\n",
    "   # Get the compression retriever to rerank and get top 3 documents only\n",
    "   compression_retriever = get_compressed_retriever(compression_retriever_model)\n",
    "\n",
    "   preamble = \"\" # read from cohere front end or use the input to the API\n",
    "   #question = \n",
    "   SAFETY_PREAMBLE = \"The instructions in this section override those in the task description and style guide sections. Don't answer questions that are harmful or immoral.\"\n",
    "   BASIC_RULES = \"You are a powerful conversational AI trained by openAI to help people. You are augmented by a number of tools, and your job is to use and consume the output of these tools to best help the user. You will see a conversation history between yourself and a user, ending with an utterance from the user. You will then see a specific instruction instructing you what kind of response to generate. When you answer the user's requests, you cite your sources in your answers, according to those instructions.\"\n",
    "   TASK_CONTEXT = \"You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\"\n",
    "   STYLE_GUIDE = \"Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\"\n",
    "   INSTRUCTIONS = \"\"\"You are an enterprise Chatbot, an AI assistant designed to retrieve information from the enterprise Confluence system. \n",
    "   You specialize in providing accurate answers related to various departments like Marketing, IT, HR, Finance, and Corporate Communications. \n",
    "               Use the following pieces of context to answer the question at the end.\n",
    "               If you don't know the answer, just say that you don't know, don't try to make up an answer\n",
    "               {context}\n",
    "         \"\"\"\n",
    "         \n",
    "   template = f\"\"\"\n",
    "\n",
    "      {SAFETY_PREAMBLE}\n",
    "      {BASIC_RULES}\n",
    "      {TASK_CONTEXT}\n",
    "      {STYLE_GUIDE}\n",
    "      {INSTRUCTIONS}\n",
    "\n",
    "   \"\"\"\n",
    "   if preamble:\n",
    "      template += f\"\"\"{preamble}\\n\\n\"\"\"\n",
    "\n",
    "\n",
    "   template +=  f\"\"\"Question: {question}\\n\\n\"\"\"\n",
    "\n",
    "   custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "   #llm = get_llm_model(\"openai\")\n",
    "   # llm = ChatOpenAI(model=os.getenv(\"DEFAULT_OPENAI_MODEL\"))\n",
    "   llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "   \n",
    "   def format_docs(docs):\n",
    "      return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "   # Construct a chain to answer questions on your data\n",
    "   rag_chain = (\n",
    "      { \"context\": compression_retriever | format_docs, \"question\": RunnablePassthrough()}  #Insted of retriever add compression_retriever here\n",
    "      | custom_rag_prompt\n",
    "      | llm\n",
    "      | StrOutputParser()\n",
    "   )\n",
    "\n",
    "   # Prompt the chain\n",
    "   question = question\n",
    "   answer = rag_chain.invoke(question)\n",
    "   similar = retriever.invoke(question)\n",
    "\n",
    "\n",
    "   return{\n",
    "      'answer': answer,\n",
    "      'contexts': [str(doc) for doc in similar]\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cohere\n",
    "import os\n",
    "import json\n",
    "os.environ['COHERE_API_KEY'] = os.getenv('COHERE_API_KEY')\n",
    "\n",
    "def call_cohere(question):\n",
    "  # Define the API endpoint for streaming\n",
    "  url = \"http://localhost:8000/v1/chat\"\n",
    "  bearer = os.getenv('BEARER_SECRET_KEY')\n",
    "\n",
    "  # Set headers\n",
    "  headers = {\n",
    "      \"User-Id\": \"me\",\n",
    "      \"Content-Type\": \"application/json\",\n",
    "      \"Authorization\": f\"Bearer {bearer}\",\n",
    "      \"Cohere-Stream\": \"true\",  # Enable streaming for chatbot responses\n",
    "  }\n",
    "\n",
    "  # Set the message to send\n",
    "  message = question['question']\n",
    "\n",
    "  # Create the payload as a JSON dictionary\n",
    "  data = {\"message\": message}\n",
    "\n",
    "  # Send the POST request using requests\n",
    "  response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "  # Check for successful response\n",
    "  if response.status_code == 200:\n",
    "    # Handle streaming response\n",
    "    for line in response.iter_lines():\n",
    "      # Decode the response (if necessary)\n",
    "      decoded_line = line.decode(\"utf-8\")\n",
    "      # Process the received data from the stream (print it here)\n",
    "      resp = json.loads(decoded_line)\n",
    "      return{\n",
    "        'answer': resp['chat_history'][1]['message'],\n",
    "        'contexts': \"None\"\n",
    "        }\n",
    "  else:\n",
    "    return{\n",
    "        'answer': {response.status_code},\n",
    "        'contexts': \"None\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To install and configure the Tech Innovator Vector Database, follow these steps:\n",
      "\n",
      "1. **Prerequisites**:\n",
      "   - Ensure you have administrative access to \n"
     ]
    }
   ],
   "source": [
    "# Test sample\n",
    "question = {'question': \"What are the steps to install and configure the Tech Innovator Vector Database?\"}\n",
    "answer = call_openai(question)\n",
    "print(answer['answer'][:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test sample Cohere\n",
    "# question = {'question': \"How does a supportive culture impact employee engagement and align with Tech Innovators Inc.'s approach to employment relations and engagement?\"}\n",
    "# answer = call_cohere(question)\n",
    "# print(answer['answer'][:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"page_content='steps.Check the log files located in /var/log/vector_db/ for error messages.ConclusionYou have successfully installed and configured the Tech Innovator Vector Database. You can now start using it for your applications.For more information, visit the official documentation.' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca08'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='PrerequisitesEnsure you have administrative access to the server where the database will be installed.Verify that your system meets the minimum hardware and software requirements.Install the latest version of Java Development Kit (JDK).Step 1: Download the InstallerVisit the Tech Innovator Vector' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca02'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='the Tech Innovator Vector Database download page.Select the appropriate version for your operating system.Download the installer package to your local machine.Step 2: Install the DatabaseOpen a terminal or command prompt.Navigate to the directory where the installer package is located.Run the' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca03'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='vector_dbVerify that the database is running and accessible.Connect to the database using a client tool to ensure it is functioning correctly.TroubleshootingIf you encounter any issues, refer to the Tech Innovator Vector Database documentation for detailed troubleshooting steps.Check the log files' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca07'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='Downloads folder.Double-click the file to start the installation process.If prompted by a security warning, click Run to proceed.Follow the on-screen instructions to complete the installation.\\\\xa0Initial SetupOnce the installation is complete, launch the Tech Innovator CV Parser from your desktop or' metadata={'_id': {'$oid': '66dffd07dee1cfdeccbec9f5'}, 'pageid': '655380', 'department': 'IT', 'title': 'Tech Innovator CV Parser Installation Guide'}\", \"page_content='Start the Database ServiceRun the following command to start the database service:sudo systemctl start vector_dbEnable the service to start on boot:sudo systemctl enable vector_dbStep 5: Verify the InstallationCheck the status of the database service:sudo systemctl status vector_dbVerify that the' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca06'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='package is located.Run the following command to start the installation:sudo ./install_vector_db.shFollow the on-screen instructions to complete the installation.Step 3: Configure the DatabaseOpen the configuration file located at /etc/vector_db/config.yaml.Update the following settings according to' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca04'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='the InstallerVisit the official Tech Innovator website.Navigate to the Downloads section.Click on the CV Parser Software link.Choose the version compatible with your operating system.Click Download.\\\\xa0Installing the SoftwareLocate the downloaded installer file in your Downloads folder.Double-click' metadata={'_id': {'$oid': '66dffd07dee1cfdeccbec9f4'}, 'pageid': '655380', 'department': 'IT', 'title': 'Tech Innovator CV Parser Installation Guide'}\", \"page_content='settings according to your environment:Database Port: Set the port number for the database server.Data Directory: Specify the directory where data files will be stored.Log Level: Set the logging level (e.g., INFO, DEBUG).Save and close the configuration file.Step 4: Start the Database ServiceRun' metadata={'_id': {'$oid': '66dffd0adee1cfdeccbeca05'}, 'pageid': '819215', 'department': 'IT', 'title': 'Tech Innovator Vector Database Installation Guide'}\", \"page_content='IntroductionTech Innovators Inc. is committed to ensuring the security and integrity of its on-premise systems. This security policy outlines the measures and procedures to protect these systems from unauthorized access, data breaches, and other security threats. This policy applies to all' metadata={'_id': {'$oid': '66dffd00dee1cfdeccbec9cb'}, 'pageid': '491546', 'department': 'IT', 'title': 'Tech Innovators Inc. On-Premise System Security Policy'}\"]\n"
     ]
    }
   ],
   "source": [
    "print(answer['contexts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG pipeline evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data set prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def json_to_dataframe(json_file_path):\n",
    "  \"\"\"Reads a JSON file and converts it to a pandas DataFrame.\n",
    "\n",
    "  Args:\n",
    "    json_file_path (str): The path to the JSON file.\n",
    "\n",
    "  Returns:\n",
    "    pandas.DataFrame: The DataFrame created from the JSON data.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(json_file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "  # Handle different JSON structures\n",
    "  if isinstance(data, list):\n",
    "    # If the JSON data is a list of dictionaries, create a DataFrame directly\n",
    "    df = pd.DataFrame(data)\n",
    "  elif isinstance(data, dict):\n",
    "    # If the JSON data is a single dictionary, convert it to a list of dictionaries\n",
    "    df = pd.DataFrame([data])\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported JSON structure\")\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "from from_root import from_root\n",
    "import os\n",
    "folder = \"data/test_dataset/test_dataset_it.json\"\n",
    "# json_file_path = os.path.join(from_root(), folder)\n",
    "# data_to_upload = json_to_dataframe(json_file_path)\n",
    "data_to_upload = json_to_dataframe(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.cohere.com/v1/rerank \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Generate all the answers for the questions in the dataset\n",
    "# examples = client.list_examples(dataset_name=\"hr test\")\n",
    "answers = []\n",
    "for question in data_to_upload['question']:\n",
    "    question_dict = {'question': question}\n",
    "    answer = call_openai(question_dict)\n",
    "    answers.append(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohere_answers = []\n",
    "# for question in data_to_upload['question']:\n",
    "#     question_dict = {'question': question}\n",
    "#     answer = call_cohere(question_dict)\n",
    "#     cohere_answers.append(answer['answer'])\n",
    "# cohere_answers = [\n",
    "#     \"To install and configure the Tech Innovator Vector Database, you must first download the installer from the Tech Innovator Vector Database download page. Then, select the appropriate version for your operating system and download it.\",\n",
    "#     \"I'm sorry, but I can't find the specific error message that John Doe received when attempting to access the Marketing database. All I can tell you is that he was unable to access it from his workstation.\",\n",
    "#     \"Tech Innovators Inc. is committed to protecting the confidentiality, integrity and availability of its data and resources hosted on Microsoft Azure.\",\n",
    "#     \"The settings that need to be updated in the configuration file for the Tech Innovator Vector Database are the database port and the port number for the database server.\",\n",
    "#     \"The mission of Tech Innovators Inc. is to drive innovation and deliver software development, IT consulting, and digital transformation services.\",\n",
    "#     \"I'm sorry, I can't find any information about the strategies Tech Innovators Inc. uses to protect its Azure and on-premise systems.\",\n",
    "#     \"To install the Tech Innovator Vector Database on a compatible operating system, you need to have the latest version of the Java Development Kit (JDK).\",\n",
    "#     \"To install the Tech Innovator CV Parser, you need to:1. Choose the version compatible with your operating system.2. Click Download. 3. Locate the downloaded installer file in your Downloads.\",\n",
    "#     \"The commands to start and enable the Tech Innovator Vector DB service are: 1.`sudo systemctl start vector_db` 2. `sudo systemctl enable vector_db`\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare data for Cohere\n",
    "# data_to_upload_cohere = data_to_upload[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dataset with answers\n",
    "data_to_upload['answers'] = answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_upload_cohere['answers'] = cohere_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "question = list(data_to_upload['question'])\n",
    "answer = list(data_to_upload['answers'])\n",
    "contexts = list(data_to_upload['contexts'])\n",
    "ground_truth = list(data_to_upload['ground_truth'])\n",
    "\n",
    "data_samples = {\n",
    "    'question': question,\n",
    "    'answer': answer,\n",
    "    'contexts': contexts,\n",
    "    'ground_truth': ground_truth\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change for Cohere\n",
    "# from datasets import Dataset\n",
    "\n",
    "# question = list(data_to_upload_cohere['question'])\n",
    "# answer = list(data_to_upload_cohere['answers'])\n",
    "# contexts = list(data_to_upload_cohere['contexts'])\n",
    "# ground_truth = list(data_to_upload_cohere['ground_truth'])\n",
    "\n",
    "# data_samples_cohere = {\n",
    "#     'question': question,\n",
    "#     'answer': answer,\n",
    "#     'contexts': contexts,\n",
    "#     'ground_truth': ground_truth\n",
    "# }\n",
    "\n",
    "# dataset_cohere = Dataset.from_dict(data_samples_cohere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   3%|▎         | 1/36 [00:01<00:44,  1.28s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   6%|▌         | 2/36 [00:02<00:39,  1.16s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:   8%|▊         | 3/36 [00:04<00:58,  1.77s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  36%|███▌      | 13/36 [00:04<00:05,  4.04it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  44%|████▍     | 16/36 [00:05<00:05,  3.71it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  50%|█████     | 18/36 [00:09<00:11,  1.60it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  75%|███████▌  | 27/36 [00:10<00:02,  3.02it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  81%|████████  | 29/36 [00:12<00:02,  2.72it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  89%|████████▉ | 32/36 [00:12<00:01,  3.49it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  94%|█████████▍| 34/36 [00:13<00:00,  2.65it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating:  97%|█████████▋| 35/36 [00:15<00:00,  1.88it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Evaluating: 100%|██████████| 36/36 [00:19<00:00,  1.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.7609, 'faithfulness': 0.7630, 'context_recall': 1.0000, 'context_precision': 1.0000}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "# from ragas.integrations.langsmith import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        answer_relevancy,\n",
    "        faithfulness,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ],\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Cohere\n",
    "from ragas import evaluate\n",
    "# from ragas.integrations.langsmith import evaluate\n",
    "# from ragas.metrics import (\n",
    "#     answer_relevancy,\n",
    "#     faithfulness,\n",
    "#     context_recall,\n",
    "#     context_precision,\n",
    "# )\n",
    "# result = evaluate(\n",
    "#     dataset_cohere,\n",
    "#     metrics=[\n",
    "#         answer_relevancy,\n",
    "#         faithfulness,\n",
    "#         context_recall,\n",
    "#         context_precision,\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To install and configure the Tech Innovator Vector Database, follow these steps:\\n\\n1. **Prerequisites**:\\n   - Ensure you have administrative access to the server where the database will be installed.\\n   - Verify that your system meets the minimum hardware and software requirements.\\n   - Install the latest version of the Java Development Kit (JDK).\\n\\n2. **Step 1: Download the Installer**:\\n   - Visit the Tech Innovator Vector Database download page.\\n   - Select the appropriate version for your operating system.\\n   - Download the installer package to your local machine.\\n\\n3. **Step 2: Install the Database**:\\n   - Open a terminal or command prompt.\\n   - Navigate to the directory where the installer package is located.\\n   - Run the installer package to initiate the installation process.\\n\\n4. **Step 3: Configuration**:\\n   - Follow any on-screen instructions to complete the configuration process for the database.\\n\\n5. **Step 4: Check for Errors** (if necessary):\\n   - After installation, you can check the log files located in `/var/log/vector_db/` for any error messages.\\n\\nOnce you have completed these steps, you will have successfully installed and configured the Tech Innovator Vector Database, and you can start using it for your applications. For more information, visit the official documentation.',\n",
       " 'John Doe received the error message: \"Database connection failed: Access denied.\" when attempting to access the Marketing database.',\n",
       " 'The security policy of Tech Innovators Inc. outlines several measures to protect data and resources hosted on Microsoft Azure. While the specific details are not provided in the context, typical measures in such policies generally include:\\n\\n1. **Access Controls**: Implementing strict access controls to ensure that only authorized personnel can access Azure services and data.\\n\\n2. **Data Encryption**: Utilizing encryption for data at rest and in transit to prevent unauthorized access and ensure data confidentiality.\\n\\n3. **Monitoring and Logging**: Establishing monitoring and logging mechanisms to detect and respond to security incidents promptly.\\n\\n4. **Incident Response**: Developing an incident response plan to address potential security breaches effectively.\\n\\n5. **Regular Audits and Assessments**: Conducting regular security audits and assessments to identify vulnerabilities and ensure compliance with security standards.\\n\\n6. **Training and Awareness**: Providing training to employees, contractors, and vendors on security best practices and the importance of data protection.\\n\\nThese measures aim to ensure the confidentiality, integrity, and availability of the data and resources hosted on Microsoft Azure. For specific details, you may need to refer to the full security policy document of Tech Innovators Inc.',\n",
       " 'To update the settings in the configuration file for the Tech Innovator Vector Database, you need to open the configuration file located at `/etc/vector_db/config.yaml`. The specific settings that need to be updated are typically detailed in the official documentation, but common settings may include parameters such as database connection details, authentication credentials, and performance tuning options. \\n\\nUnfortunately, the exact settings to update were not provided in the context, so I recommend referring to the official documentation for the Tech Innovator Vector Database for precise instructions on the necessary configuration settings.',\n",
       " \"I don't know the specific mission of the Tech Innovators Inc IT team as that information is not provided in the context you've shared.\",\n",
       " 'Tech Innovators Inc. employs several strategies to protect its Azure and on-premise systems, focusing on ensuring the security, confidentiality, integrity, and availability of its data and resources. While the specific measures are not detailed in the provided context, typical strategies in such policies may include:\\n\\n1. **Access Control**: Implementing strict access controls to ensure that only authorized personnel have access to sensitive data and systems.\\n\\n2. **Data Encryption**: Utilizing encryption for data at rest and in transit to protect against unauthorized access and data breaches.\\n\\n3. **Regular Security Audits**: Conducting ongoing security assessments and audits to identify and mitigate potential vulnerabilities in both Azure and on-premise systems.\\n\\n4. **Network Security Measures**: Utilizing firewalls, intrusion detection systems, and secure network configurations to protect network devices and data.\\n\\n5. **Employee Training**: Providing training and awareness programs for employees, contractors, and third-party vendors to recognize and respond to security threats effectively.\\n\\n6. **Incident Response Planning**: Establishing a robust incident response plan to quickly address and mitigate any security incidents.\\n\\n7. **Backup and Recovery Procedures**: Implementing regular backup processes and disaster recovery plans to ensure data availability and integrity during incidents.\\n\\nThese strategies are designed to create a comprehensive security posture for both Azure and on-premise environments.',\n",
       " 'To install the Tech Innovator Vector Database on a compatible operating system, you need to follow these steps:\\n\\n1. **Prerequisites**:\\n   - Ensure you have administrative access to the server where the database will be installed.\\n   - Verify that your system meets the minimum hardware and software requirements.\\n   - Install the latest version of the Java Development Kit (JDK).\\n\\n2. **Step 1: Download the Installer**:\\n   - Visit the Tech Innovator Vector Database download page.\\n   - Select the appropriate version for your operating system.\\n   - Download the installer package to your local machine.\\n\\n3. **Step 2: Install the Database**:\\n   - Open a terminal or command prompt.\\n   - Navigate to the directory where the installer package is located.\\n   - Run the installer package.\\n\\nAfter installation, you can check the log files located in `/var/log/vector_db/` for any error messages and ensure that the installation was successful. For more detailed instructions, refer to the official documentation.',\n",
       " 'To install the Tech Innovator CV Parser and Vector Database, the following key system and access needs must be met:\\n\\n1. **Administrative Access**: Ensure you have administrative access to the server or machine where the software will be installed.\\n\\n2. **Minimum System Requirements**: Verify that your system meets the minimum hardware and software requirements specified by Tech Innovator for both the CV Parser and the Vector Database.\\n\\n3. **Java Development Kit (JDK)**: Install the latest version of the Java Development Kit (JDK), as it is a prerequisite for running the Vector Database.\\n\\nBy fulfilling these requirements, you can proceed with the installation of both software applications effectively.',\n",
       " 'To start and enable the Tech Innovator Vector Database service, you can use the following commands:\\n\\n1. To start the database service:\\n   ```bash\\n   sudo systemctl start vector_db\\n   ```\\n\\n2. To enable the service to start on boot:\\n   ```bash\\n   sudo systemctl enable vector_db\\n   ```\\n\\nThese commands will ensure that the Vector Database service is running and set to start automatically when the system boots up.']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohere_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the steps to install and configure th...</td>\n",
       "      <td>To install and configure the Tech Innovator Ve...</td>\n",
       "      <td>[Prerequisites\\nEnsure you have administrative...</td>\n",
       "      <td>The steps to install and configure the Tech In...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What error message did John Doe receive when a...</td>\n",
       "      <td>John Doe received the error message: \"Database...</td>\n",
       "      <td>[Ticket ID:\\n IT-12345\\nCreated Date:\\n July 2...</td>\n",
       "      <td>John Doe received the error message stating, \"...</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What measures does the security policy of Tech...</td>\n",
       "      <td>The security policy of Tech Innovators Inc. ou...</td>\n",
       "      <td>[Introduction\\nTech Innovators Inc. is committ...</td>\n",
       "      <td>The security policy of Tech Innovators Inc. ou...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What settings need to be updated in the config...</td>\n",
       "      <td>To update the settings in the configuration fi...</td>\n",
       "      <td>[Prerequisites\\nEnsure you have administrative...</td>\n",
       "      <td>The settings that need to be updated in the co...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the mission of the Tech Innovators Inc...</td>\n",
       "      <td>I don't know the specific mission of the Tech ...</td>\n",
       "      <td>[:check_mark:\\natlassian-check_mark\\n#F4F5F7\\n...</td>\n",
       "      <td>Our mission is to enable and empower our busin...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What strategies does Tech Innovators Inc. use ...</td>\n",
       "      <td>Tech Innovators Inc. employs several strategie...</td>\n",
       "      <td>[Introduction\\nTech Innovators Inc. is committ...</td>\n",
       "      <td>Tech Innovators Inc. employs several strategie...</td>\n",
       "      <td>0.998669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What’s needed to install the Tech Innovator Ve...</td>\n",
       "      <td>To install the Tech Innovator Vector Database ...</td>\n",
       "      <td>[Prerequisites\\nEnsure you have administrative...</td>\n",
       "      <td>To install the Tech Innovator Vector Database ...</td>\n",
       "      <td>0.927728</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the key system and access needs for i...</td>\n",
       "      <td>To install the Tech Innovator CV Parser and Ve...</td>\n",
       "      <td>[Prerequisites\\nBefore you start the installat...</td>\n",
       "      <td>The key system and access needs for installing...</td>\n",
       "      <td>0.961962</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What commands start and enable the Tech Innova...</td>\n",
       "      <td>To start and enable the Tech Innovator Vector ...</td>\n",
       "      <td>[Prerequisites\\nEnsure you have administrative...</td>\n",
       "      <td>The commands to start and enable the Tech Inno...</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the steps to install and configure th...   \n",
       "1  What error message did John Doe receive when a...   \n",
       "2  What measures does the security policy of Tech...   \n",
       "3  What settings need to be updated in the config...   \n",
       "4  What is the mission of the Tech Innovators Inc...   \n",
       "5  What strategies does Tech Innovators Inc. use ...   \n",
       "6  What’s needed to install the Tech Innovator Ve...   \n",
       "7  What are the key system and access needs for i...   \n",
       "8  What commands start and enable the Tech Innova...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  To install and configure the Tech Innovator Ve...   \n",
       "1  John Doe received the error message: \"Database...   \n",
       "2  The security policy of Tech Innovators Inc. ou...   \n",
       "3  To update the settings in the configuration fi...   \n",
       "4  I don't know the specific mission of the Tech ...   \n",
       "5  Tech Innovators Inc. employs several strategie...   \n",
       "6  To install the Tech Innovator Vector Database ...   \n",
       "7  To install the Tech Innovator CV Parser and Ve...   \n",
       "8  To start and enable the Tech Innovator Vector ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Prerequisites\\nEnsure you have administrative...   \n",
       "1  [Ticket ID:\\n IT-12345\\nCreated Date:\\n July 2...   \n",
       "2  [Introduction\\nTech Innovators Inc. is committ...   \n",
       "3  [Prerequisites\\nEnsure you have administrative...   \n",
       "4  [:check_mark:\\natlassian-check_mark\\n#F4F5F7\\n...   \n",
       "5  [Introduction\\nTech Innovators Inc. is committ...   \n",
       "6  [Prerequisites\\nEnsure you have administrative...   \n",
       "7  [Prerequisites\\nBefore you start the installat...   \n",
       "8  [Prerequisites\\nEnsure you have administrative...   \n",
       "\n",
       "                                        ground_truth  answer_relevancy  \\\n",
       "0  The steps to install and configure the Tech In...          1.000000   \n",
       "1  John Doe received the error message stating, \"...          0.999706   \n",
       "2  The security policy of Tech Innovators Inc. ou...          1.000000   \n",
       "3  The settings that need to be updated in the co...          0.000000   \n",
       "4  Our mission is to enable and empower our busin...          0.000000   \n",
       "5  Tech Innovators Inc. employs several strategie...          0.998669   \n",
       "6  To install the Tech Innovator Vector Database ...          0.927728   \n",
       "7  The key system and access needs for installing...          0.961962   \n",
       "8  The commands to start and enable the Tech Inno...          0.959930   \n",
       "\n",
       "   faithfulness  context_recall  context_precision  \n",
       "0      1.000000             1.0                1.0  \n",
       "1      1.000000             1.0                1.0  \n",
       "2      0.733333             1.0                1.0  \n",
       "3      0.500000             1.0                1.0  \n",
       "4      0.000000             1.0                1.0  \n",
       "5      1.000000             1.0                1.0  \n",
       "6      0.833333             1.0                1.0  \n",
       "7      0.800000             1.0                1.0  \n",
       "8      1.000000             1.0                1.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cohere.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
