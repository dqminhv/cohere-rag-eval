{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why synthetic test data?**\n",
    "Evaluating RAG (Retrieval-Augmented Generation) augmented pipelines is crucial for assessing their performance. However, manually creating hundreds of QA (Question-Context-Answer) samples from documents can be time-consuming and labor-intensive. Additionally, human-generated questions may struggle to reach the level of complexity required for a thorough evaluation, ultimately impacting the quality of the assessment. By using synthetic data generation developer time in data aggregation process can be reduced by 90%.\n",
    "\n",
    "**How does Ragas differ in test data generation?**\n",
    "Ragas takes a novel approach to evaluation data generation. An ideal evaluation dataset should encompass various types of questions encountered in production, including questions of varying difficulty levels. LLMs by default are not good at creating diverse samples as it tends to follow common paths. Inspired by works like Evol-Instruct, Ragas achieves this by employing an evolutionary generation paradigm, where questions with different characteristics such as reasoning, conditioning, multi-context, and more are systematically crafted from the provided set of documents. This approach ensures comprehensive coverage of the performance of various components within your pipeline, resulting in a more robust evaluation process.\n",
    "\n",
    "evol-generate\n",
    "\n",
    "**In-Depth Evolution**\n",
    "Large Language Models (LLMs) possess the capability to transform simple questions into more complex ones effectively. To generate medium to hard samples from the provided documents, we employ the following methods:\n",
    "\n",
    "* Reasoning: Rewrite the question in a way that enhances the need for reasoning to answer it effectively.\n",
    "\n",
    "* Conditioning: Modify the question to introduce a conditional element, which adds complexity to the question.\n",
    "\n",
    "* Multi-Context: Rephrase the question in a manner that necessitates information from multiple related sections or chunks to formulate an answer.\n",
    "\n",
    "Moreover, our paradigm extends its capabilities to create conversational questions from the given documents:\n",
    "\n",
    "* Conversational: A portion of the questions, following the evolution process, can be transformed into conversational samples. These questions simulate a chat-based question-and-follow-up interaction, mimicking a chat-Q&A pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic test data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs the test data generation using RAGAS generator. It takes in a set of json files, which are documents of Tech Innovator Inc from its Confluence pages, and generate a set of [questions & answers & contexts]. These data serve as the reference for RAG pipeline evaluation.\n",
    "\n",
    "RAGAS synthetic test data generator requires 3 core parameters:\n",
    "* Genarating agent: an LLM to generate Q&As from a set of documents\n",
    "* Embedding model\n",
    "* Critic agent: an LLM serve as a quality control agent. It will filter-out bad Q&As generated by the generating agent \n",
    "\n",
    "The test dataset is then uploaded to the LangSmith account for later use in RAG evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load the .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that takes in .json files and return a list of langchain documents\n",
    "import json\n",
    "import langchain\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "\n",
    "def load_json_files_to_documents(directory):\n",
    "  \"\"\"Loads JSON files from a given directory into a list of Langchain Documents.\n",
    "\n",
    "  Args:\n",
    "    directory: The path to the directory containing JSON files.\n",
    "\n",
    "  Returns:\n",
    "    A list of Langchain Documents.\n",
    "  \"\"\"\n",
    "\n",
    "  documents = []\n",
    "  for filename in os.listdir(directory):\n",
    "      if filename.endswith('.json'):\n",
    "          file_path = os.path.join(directory, filename)\n",
    "          with open(file_path, 'r') as f:\n",
    "              data = json.load(f)\n",
    "              # Extract relevant fields from the JSON data\n",
    "              content = data['text']  # Replace 'content' with the actual field name\n",
    "              metadata = {'source': filename}  # Add additional metadata if needed\n",
    "              document = LangchainDocument(page_content=content, metadata=metadata)\n",
    "              documents.append(document)\n",
    "  return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json files of documents from Confluence\n",
    "# Example usage: Read json files of HR Department\n",
    "from from_root import from_root\n",
    "department = \"data\\HR\" # -> Choose the department you would like to generate synthetic data\n",
    "documents = load_json_files_to_documents(os.path.join(from_root(), department))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a generative agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LLMs from OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"DEFAULT_OPENAI_MODEL\") # -> Choose your desired model\n",
    "generator_llm = ChatOpenAI(model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same embedding model when embedding documents from Confluence\n",
    "# OpenAI Embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "embeddings = OpenAIEmbeddings(disallowed_special=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a critic agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the critic agent must be different than the generating agent. However, due to API call limit issue, I skip creating this agent. Instead, I use OpenAI as the critic agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a critic LLM. This should be different than the generative llm\n",
    "# For GROQ LLMs\n",
    "# from langchain_groq import ChatGroq\n",
    "# os.environ[\"GROD_CLOUD_API_KEY\"] = os.getenv('GROD_CLOUD_API_KEY')\n",
    "# model_name = os.getenv(\"DEFAULT_GROD_MODEL\")\n",
    "# critic_llm = ChatGroq(\n",
    "#                    groq_api_key=os.environ[\"GROD_CLOUD_API_KEY\"],\n",
    "#                    model_name=model_name\n",
    "#                    )\n",
    "\n",
    "critic_llm = generator_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the RAGAS generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "generator_test = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Change resulting question type distribution (This is where we determine the distribution of question types in the test dataset)\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# Setting the number of Q&As to be in the dataset. \n",
    "# Note: the final test dataset size might be smaller than this since the critic agent may filtered out some of the bad Q&As.\n",
    "testset_size = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate the test dataset with the above configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\n",
    "\n",
    "testset = generator_test.generate_with_langchain_docs(documents, testset_size, distributions, with_debugging_logs=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What information should be included in the pol...</td>\n",
       "      <td>[2\\n2\\n Welcome to \\n&lt;Company&gt;\\n!\\nAdd a welco...</td>\n",
       "      <td>List and describe the policies, procedures, an...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Template - Employee handbook.json'}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Tech Innovators Inc.'s policy on remot...</td>\n",
       "      <td>[Q12: What is the process for handling workpla...</td>\n",
       "      <td>Tech Innovators Inc. supports flexible working...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Employee Frequently Asked Questio...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does Tech Innovators Inc. strive to create...</td>\n",
       "      <td>[ Inc. upholds the highest ethical standards i...</td>\n",
       "      <td>Tech Innovators Inc. strives to create a diver...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Tech Innovators Inc. Recruitment ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can past performance reviews be used for s...</td>\n",
       "      <td>[ Self-assessment\\nStart by thinking through y...</td>\n",
       "      <td>Start by thinking through your existing streng...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Template - Career development pla...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the role of mentorship in the onboardi...</td>\n",
       "      <td>[Welcome to Tech Innovators Inc.\\n \\nWe are th...</td>\n",
       "      <td>Mentorship plays a crucial role in the onboard...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'Tech Innovators Inc. Employee Onb...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What support does Tech Innovators Inc. provide...</td>\n",
       "      <td>[Table of Contents\\nTraining and Development\\n...</td>\n",
       "      <td>nan</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Employee Frequently Asked Questio...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do employee engagement and disengagement d...</td>\n",
       "      <td>[Introduction\\nAt Tech Innovators Inc., we bel...</td>\n",
       "      <td>Employee engagement and disengagement differ i...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Employee Relations and Engagement...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the purpose of regular HR audits for c...</td>\n",
       "      <td>[5.2 Monitoring and Auditing\\nInternal Audits\\...</td>\n",
       "      <td>Regular HR audits for compliance with labor la...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'Tech Innovators Inc. Compliance w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Which section of the employee handbook covers ...</td>\n",
       "      <td>[Table of Contents\\nTraining and Development\\n...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'Employee Frequently Asked Questio...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What information should be included in the pol...   \n",
       "1  What is Tech Innovators Inc.'s policy on remot...   \n",
       "2  How does Tech Innovators Inc. strive to create...   \n",
       "3  How can past performance reviews be used for s...   \n",
       "4  What is the role of mentorship in the onboardi...   \n",
       "5  What support does Tech Innovators Inc. provide...   \n",
       "6  How do employee engagement and disengagement d...   \n",
       "7  What is the purpose of regular HR audits for c...   \n",
       "8  Which section of the employee handbook covers ...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [2\\n2\\n Welcome to \\n<Company>\\n!\\nAdd a welco...   \n",
       "1  [Q12: What is the process for handling workpla...   \n",
       "2  [ Inc. upholds the highest ethical standards i...   \n",
       "3  [ Self-assessment\\nStart by thinking through y...   \n",
       "4  [Welcome to Tech Innovators Inc.\\n \\nWe are th...   \n",
       "5  [Table of Contents\\nTraining and Development\\n...   \n",
       "6  [Introduction\\nAt Tech Innovators Inc., we bel...   \n",
       "7  [5.2 Monitoring and Auditing\\nInternal Audits\\...   \n",
       "8  [Table of Contents\\nTraining and Development\\n...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  List and describe the policies, procedures, an...         simple   \n",
       "1  Tech Innovators Inc. supports flexible working...         simple   \n",
       "2  Tech Innovators Inc. strives to create a diver...         simple   \n",
       "3  Start by thinking through your existing streng...         simple   \n",
       "4  Mentorship plays a crucial role in the onboard...         simple   \n",
       "5                                                nan  multi_context   \n",
       "6  Employee engagement and disengagement differ i...  multi_context   \n",
       "7  Regular HR audits for compliance with labor la...  multi_context   \n",
       "8  The answer to given question is not present in...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'Template - Employee handbook.json'}]          True  \n",
       "1  [{'source': 'Employee Frequently Asked Questio...          True  \n",
       "2  [{'source': 'Tech Innovators Inc. Recruitment ...          True  \n",
       "3  [{'source': 'Template - Career development pla...          True  \n",
       "4  [{'source': 'Tech Innovators Inc. Employee Onb...          True  \n",
       "5  [{'source': 'Employee Frequently Asked Questio...          True  \n",
       "6  [{'source': 'Employee Relations and Engagement...          True  \n",
       "7  [{'source': 'Tech Innovators Inc. Compliance w...          True  \n",
       "8  [{'source': 'Employee Frequently Asked Questio...          True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the test dataset to a pandas dataframe and print it out\n",
    "test_df = testset.to_pandas()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the result to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the resulting test dataset to a json file\n",
    "from from_root import from_root\n",
    "file_name = \"test_dataset_hr.json\"\n",
    "test_df[['question', 'ground_truth']].to_json(os.path.join(from_root(), 'data-test/test-dataset/',file_name), orient='records', indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
